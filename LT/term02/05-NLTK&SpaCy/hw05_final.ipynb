{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd02759-1cda-484b-92ea-7772c6429596",
   "metadata": {},
   "source": [
    "## Итоговое домашнее задание\n",
    "\n",
    "Для выполнения этого задания выберите два любых достаточно длинных текста (.txt) на русском и на любом другом (для которого есть парсеры) языке; если возьмете текст и его перевод, будет отлично. \n",
    "\n",
    "In order to complete these tasks choose two long texts (.txt files) in Russian and in any other language (assumed that there are parsers for it). If you find a text and its translation, it will be more interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5dcc1a-4046-481a-9f77-d22065b69382",
   "metadata": {},
   "source": [
    "#### Задача 1. \n",
    "\n",
    "Просмотрите оба выбранных текста. Удостоверьтесь, что тексты чистые, если же в них есть какой-то мусор: хештеги, затесавшиеся при OCR символы и подобное, почистите с помощью регулярных выражений. \n",
    "\n",
    "Проведите первичный статистический анализ: разбейте тексты на предложения и на токены, посчитайте относительное количество того и другого, сопоставьте. Если ваши тексты параллельные, какой длиннее? В каком тексте средняя длина предложения больше? Почему? В каком тексте выше лексическое разнообразие? \n",
    "\n",
    "Таким образом, вам необходимо узнать следующие вещи:\n",
    "\n",
    "- количество предложений (относительное и абсолютное)\n",
    "- количество токенов (относительное и абсолютное)\n",
    "- средняя длина предложения (среднее количество слов в предложении)\n",
    "- соотношение \"уникальные токены / все токены\"\n",
    "- (опционально) соотношение знаков пунктуации и слов\n",
    "\n",
    "Look through your chosen texts. If the texts are not clean (that is, if there are any hashtags or meaningless symbols left after optical character recognition), clean them with the help of regular expressions.\n",
    "\n",
    "Let's analyze the texts from the point of view of statistics: especially if your texts are parallel (translate one another), it is interesting to know the difference between them. You should find:\n",
    "\n",
    "- the quantity of sentences (relative and absolute)\n",
    "- the quantity of tokens (relative and absolute)\n",
    "- the mean length of a sentence (mean number of words in a sentence)\n",
    "- the proportion \"unique token number / all tokens number\"\n",
    "- (optionally) the proportion of punctuation marks and meaningful words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e9f95e-6091-4c9f-afcb-fd266ad561a3",
   "metadata": {},
   "source": [
    "#### Задача 2. \n",
    "\n",
    "Сделайте морфосинтаксические разборы ваших текстов в формате UD, запишите .conllu-файлы. \n",
    "\n",
    "Parse your texts morphologically in UD format, write .conllu-files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f40e82-520e-456a-8498-aea94f239467",
   "metadata": {},
   "source": [
    "#### Задача 3. \n",
    "\n",
    "Посчитайте статистику по частям речи, сопоставьте: можно напечатать две таблички с процентами по частям речи. \n",
    "\n",
    "Count POS statistics for both texts: there should be two tables with POS-tags and their quantity in the text, e.g. NOUN 23%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739bdf0e-92f0-4325-8495-1b690e29b52c",
   "metadata": {},
   "source": [
    "#### Задача 4. \n",
    "\n",
    "Посчитайте, какое соотношение токенов по частям речи имеет совпадающие со словоформой леммы (т.е., в скольких случаях токены с частью речи VERB, например, имели словарную форму: и сам токен, и лемма одинаковые). Что вы можете сказать о выбранных вами языках на основании этих данных? Ожидаются две таблички с процентами несовпадающих по лемме и токену слов для каждой части речи. \n",
    "\n",
    "Find out the proportions of tokens whose lemmas differ from their form by POS (e.g., if 30 Nouns out of 100 have different lemmas: 'стола' vs 'стол', then you should print NOUN 30%). What can you say about your languages based on this data? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659adbbd-f0d9-419d-8b5f-9c15096917cd",
   "metadata": {},
   "source": [
    "#### Задача 5. \n",
    "\n",
    "Посчитайте медианную длину предложения для ваших текстов (медиана - это если взять все длины всех ваших предложений, упорядочить их от маленького к большому и выбрать то число, которое оказалось посередине, а если чисел четное количество, то взять среднее арифметическое двух чисел посередине. Например, если у вас пять предложений длинами 1, 2, 6, 7, 8, то медиана - 6, а если шесть предложений длинами 1, 1, 7, 9, 10, 11, то медиана - (7 + 9) / 2 = 8). Возьмите любые два предложения (одно русское и второе на другом языке) и постройте для них деревья зависимостей. Изучите связи зависимостей (deprel) и вершины: согласны ли вы с разбором?\n",
    "\n",
    "Count median length of a sentence for your text (median is a number which is in the middle of all your sorted sentence length, e.g. if you have five sentences with the lengths 1, 2, 6, 7, 8, then your median is 6, and if there is an even number: 1, 1, 7, 9, 10, 11, then your median is calculated as (7 + 9) / 2 = 8). \n",
    "\n",
    "Take any two sentences with median lengths and build dependency trees (with displacy or any service for .conllu files). Look at dependency relations and their heads: do you agree with this parsing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8366f-37c6-489c-b405-7ad5d2a9a121",
   "metadata": {},
   "source": [
    "#### Задача 6. \n",
    "\n",
    "Посчитайте частотные списки токенов для каждой категории связей зависимостей (т.е., нужно выделить все токены в тексте, которые получали, например, ярлык amod, и посчитать их частоты). Выведите по первые три самых частотных токена для каждой категории (punct можно не выводить). \n",
    "\n",
    "Count frequency lists of tokens for each dependency relation category (e.g., for amod relation you should get all tokens which are labelled amod and count their frequencies). Print three first most frequent tokens for each category except for punct. Your result should look like this:\n",
    "\n",
    "    amod: beautiful, ugly, pretty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
