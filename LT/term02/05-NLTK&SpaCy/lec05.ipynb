{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c7811d2-97ea-4df0-8fa0-2404d8407c87",
   "metadata": {},
   "source": [
    "### Крупные библиотеки NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703ebf4e-f527-4c89-983a-cf4d0ca023db",
   "metadata": {},
   "source": [
    "#### NLTK\n",
    "\n",
    "NLTK - одна из самых первых библиотек такого рода; она огромная и содержит очень много разных инструментов, некоторые из них никак не связаны между собой (в отличие от spacy). NLTK - больше исследовательская библиотека, конструктор своего рода. Для NLTK есть учебник, написанный авторами: [NLTK book](https://www.nltk.org/book/). Для этого учебника специально существует подмодуль book, который обычно импортируется целиком:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8c2c1-9b70-4a85-aa61-35ad0c5fdc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a286817-46d8-41f8-9467-a49cae5f69b1",
   "metadata": {},
   "source": [
    "В этом модуле есть некий набор текстов и набор предложений, с которыми можно поиграться. \n",
    "\n",
    "Центральный объект для NLTK (по крайней мере, при работе с корпусами) - это Text (nltk.text.Text). По сути, в этом объекте содержится сам текст в виде списка токенов, но у него есть дополнительные методы. Что можно делать с объектом класса Text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8cee082-984d-4b57-942e-c7353ba01a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 84 matches:\n",
      "[ Moby Dick by Herman Melville 1851 ] ETYMOLOGY . ( Su\n",
      "hat white whale must be the same that some call Moby Dick .\" \" Moby Dick ?\" shouted Ahab . \" Do ye k\n",
      " must be the same that some call Moby Dick .\" \" Moby Dick ?\" shouted Ahab . \" Do ye know the white w\n",
      "ib in a squall . Death and devils ! men , it is Moby Dick ye have seen -- Moby Dick -- Moby Dick !\" \n",
      " devils ! men , it is Moby Dick ye have seen -- Moby Dick -- Moby Dick !\" \" Captain Ahab ,\" said Sta\n"
     ]
    }
   ],
   "source": [
    "text1.concordance('Moby', width=100, lines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3297d5-a431-40dd-abbf-cf7d460b9680",
   "metadata": {},
   "source": [
    "Конкорданс ищет первые n вхождений заданного слова с шириной контекста width. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca51a7c-c6b9-4f33-8f93-f8f9a19b15c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship boat sea time captain world man deck pequod other whales air\n",
      "water head crew line thing side way body\n"
     ]
    }
   ],
   "source": [
    "text1.similar('whale', num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858af827-615f-4d88-af12-40caab1edf1e",
   "metadata": {},
   "source": [
    "similar возвращает num слов, которые встречаются в похожих контекстах (дистрибутивная похожесть). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f0f528-bfc4-47bc-9d44-9810d6a84de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the_s the_and the_is the_in the_the the_as the_was the_which the_i\n",
      "a_in the_has the_when the_had the_with the_to the_by the_so the_that\n",
      "the_would the_a\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts(['whale', 'ship'])  # тоже можно задать параметр num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9003fb-f5a9-43a6-b58b-d7c32e0a7df7",
   "metadata": {},
   "source": [
    "common_contexts ищет те самые совпадающие контексты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93522132-8208-4d28-81f9-8c40da92d295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text1.dispersion_plot(['Ahab', 'Ishmael'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62a3090-3af9-43b8-8d62-d6fe5910d38b",
   "metadata": {},
   "source": [
    "Можно построить график распределения слов по тексту (без NumPy и matplotlib график не работает, поэтому установите эти две библиотеки, если еще не). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ad155d-610a-4b7b-ba3a-5051a49314dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count('Moby')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4bcfc-65e5-41b7-ab2b-777054a47be1",
   "metadata": {},
   "source": [
    "Можно посчитать количество вхождений какого-то слова. Кстати, к текстам можно применять обычные функции len(), set() и подобные. И срезы с индексами работают!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a2831d-2507-4188-8235-51d3901063a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building ngram index...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long , from one to the top - mast , and no coffin and went out a sea\n",
      "captain -- this peaking of the whales . , so as to preserve all his\n",
      "might had in former years abounding with them , they toil with their\n",
      "lances , strange tales of Southern whaling . at once the bravest\n",
      "Indians he was , after in vain strove to pierce the profundity . ?\n",
      "then ?\" a levelled flame of pale , And give no chance , watch him ;\n",
      "though the line , it is to be gainsaid . have been\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'long , from one to the top - mast , and no coffin and went out a sea\\ncaptain -- this peaking of the whales . , so as to preserve all his\\nmight had in former years abounding with them , they toil with their\\nlances , strange tales of Southern whaling . at once the bravest\\nIndians he was , after in vain strove to pierce the profundity . ?\\nthen ?\" a levelled flame of pale , And give no chance , watch him ;\\nthough the line , it is to be gainsaid . have been'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.generate(length=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de247f08-36c7-4487-98ac-936c542f584d",
   "metadata": {},
   "source": [
    "Можно сгенерировать текст, \"похожий\" на оригинальный. Это делается с помощью n-грамов (или n-грамм, я видела разные варианты по-русски...): nltk просто в случайном порядке совмещает эти n-грамы. Как можно видеть, не слишком полезный метод, однако можно побаловаться. \n",
    "\n",
    "Важнее то, что в nltk есть утилиты для работы с n-грамами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de80d6c8-3ea3-4468-abc1-edf674934ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 'suburb', 'of'),\n",
       " ('suburb', 'of', 'Saffron'),\n",
       " ('of', 'Saffron', 'Park'),\n",
       " ('Saffron', 'Park', 'lay'),\n",
       " ('Park', 'lay', 'on'),\n",
       " ('lay', 'on', 'the'),\n",
       " ('on', 'the', 'sunset'),\n",
       " ('the', 'sunset', 'side'),\n",
       " ('sunset', 'side', 'of'),\n",
       " ('side', 'of', 'London'),\n",
       " ('of', 'London', ','),\n",
       " ('London', ',', 'as'),\n",
       " (',', 'as', 'red'),\n",
       " ('as', 'red', 'and'),\n",
       " ('red', 'and', 'ragged'),\n",
       " ('and', 'ragged', 'as'),\n",
       " ('ragged', 'as', 'a'),\n",
       " ('as', 'a', 'cloud'),\n",
       " ('a', 'cloud', 'of'),\n",
       " ('cloud', 'of', 'sunset'),\n",
       " ('of', 'sunset', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams # bigrams\n",
    "\n",
    "list(ngrams(sent9, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f3cb8d-1a72-473c-8c87-6ac613823b6e",
   "metadata": {},
   "source": [
    "Функция ngrams (или bigrams) возвращает список всех н-грамов списка токенов, который ей дать. N-грамы еще принимают число n. \n",
    "\n",
    "У класса Text есть метод, который возвращает коллокации (частотные н-грамы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "324c9c7f-e28d-499b-b5fa-5b157310ecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sperm Whale; Moby Dick; White Whale; old man; Captain Ahab; sperm\n",
      "whale; Right Whale; Captain Peleg; New Bedford; Cape Horn; cried Ahab;\n",
      "years ago; lower jaw; never mind; Father Mapple; cried Stubb; chief\n",
      "mate; white whale; ivory leg; one hand\n"
     ]
    }
   ],
   "source": [
    "text1.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217aa9dc-b878-45a6-b97a-b1790dbd132a",
   "metadata": {},
   "source": [
    "Как создать собственный объект класса Text? Достаточно токенизировать свой текст (любым токенизатором) и передать его в класс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997d7c1-4542-432c-8c08-ecf3ed9e14cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytext = Text(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e798d89-805e-426b-b983-0b996557e6b7",
   "metadata": {},
   "source": [
    "У nltk есть и свой токенизатор и сентенайзер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332af7e6-8354-4ba6-a348-186925778af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My', 'beautiful', 'sentence', 'is', 'here', '.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize('My beautiful sentence is here.')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20cddc4-26c3-4d5e-bc03-6819d9d741f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Можно сгенерировать текст, \"похожий\" на оригинальный.',\n",
       " 'Это делается с помощью n-грамов (или n-грамм, я видела разные варианты по-русски...): nltk просто в случайном порядке совмещает эти n-грамы.',\n",
       " 'Как можно видеть, не слишком полезный метод, однако можно побаловаться.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sents = sent_tokenize('''Можно сгенерировать текст, \"похожий\" на оригинальный. Это делается с помощью n-грамов (или n-грамм, я видела разные варианты по-русски...): nltk просто в случайном порядке совмещает эти n-грамы. Как можно видеть, не слишком полезный метод, однако можно побаловаться.''')\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8271443-2d4a-4e6a-b6f7-0ef2548ca813",
   "metadata": {},
   "source": [
    "#### SpaCy\n",
    "\n",
    "Спейси - более современная библиотека, которая написана в Cython и использует нейронные сети. Интерфейс спейси довольно удобный и однообразный. Центральное понятие для спейси - это pipeline: то есть, набор действий, которые спейси совершает с текстом. Чтобы обработать текст на любом из языков, представленных в библиотеке ([список](https://spacy.io/usage/models)), достаточно завести пустой пайплайн:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351df8ab-7b20-4085-a653-8d93cf831ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "doc = nlp('My beautiful sentence is here.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d75d72-a8b5-42aa-97db-03dd1ea7e632",
   "metadata": {},
   "source": [
    "Предупреждения может выдавать библиотека tensorflow, которая сообщает, что у вас не настроена CUDA, но их можно игнорировать, как и предлагается. \n",
    "\n",
    "Пустой пайплайн превращает наш текст в особый объект, в котором текст разделен на токены, и можно у этих токенов смотреть самые простые характеристики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2554fee0-908b-447c-88f1-14ff5356d343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "№ 0. Токен:              My. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 1. Токен:       beautiful. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 2. Токен:        sentence. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 3. Токен:              is. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 4. Токен:            here. Является словом: True. Является пунктуацией: False. Похож на число: False\n",
      "№ 5. Токен:               .. Является словом: False. Является пунктуацией: True. Похож на число: False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'№ {token.i}. Токен: {token.text:>15}. Является словом: {token.is_alpha}. Является пунктуацией: {token.is_punct}. Похож на число: {token.like_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699bc4b4-3f77-4d7b-a7f6-be9713e881a8",
   "metadata": {},
   "source": [
    "Объект doc также позволяет смотреть спаны (несколько токенов, срез текста):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35ef9034-e291-4565-a790-74d3ab2e1cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beautiful sentence'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc[1:3]\n",
    "span.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db71e9-21f5-43f8-a43a-359cf7521738",
   "metadata": {},
   "source": [
    "Ну, это все прекрасно, но хотелось бы чего-то большего. Для spacy есть довольно много предобученных моделей для разных языков (список см. выше). Модельки нужно устанавливать (скачивать) с помощью команды в командной строке - она написана у них на сайте (python -m spacy download имя_модели). Когда вы загрузили модельку, вы можете ее использовать в коде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771f4ce7-ace0-40e4-97ce-37fa1e51f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6e003-8525-49ac-b6fc-72c08099421f",
   "metadata": {},
   "source": [
    "Теперь уже можно получить сведения поинтереснее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fded90b9-237f-46ce-a4e5-789f93f89ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05cb3a68-dec6-4f83-822c-a90b2683fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0. The             POS: DET    SyntR: det       Head: Army\n",
      " 1. 4th             POS: ADJ    SyntR: amod      Head: Army\n",
      " 2. Army            POS: PROPN  SyntR: nsubj     Head: was\n",
      " 3. was             POS: AUX    SyntR: ROOT      Head: was\n",
      " 4. a               POS: DET    SyntR: det       Head: formation\n",
      " 5. Royal           POS: PROPN  SyntR: compound  Head: Army\n",
      " 6. Yugoslav        POS: ADJ    SyntR: amod      Head: Army\n",
      " 7. Army            POS: PROPN  SyntR: compound  Head: formation\n",
      " 8. formation       POS: NOUN   SyntR: attr      Head: was\n",
      " 9. mobilised       POS: VERB   SyntR: acl       Head: formation\n",
      "10. prior           POS: ADV    SyntR: advmod    Head: mobilised\n",
      "11. to              POS: ADP    SyntR: prep      Head: prior\n",
      "12. the             POS: DET    SyntR: det       Head: invasion\n",
      "13. German          POS: PROPN  SyntR: npadvmod  Head: led\n",
      "14. -               POS: PUNCT  SyntR: punct     Head: led\n",
      "15. led             POS: VERB   SyntR: amod      Head: invasion\n",
      "16. invasion        POS: NOUN   SyntR: pobj      Head: to\n",
      "17. of              POS: ADP    SyntR: prep      Head: invasion\n",
      "18. the             POS: DET    SyntR: det       Head: Kingdom\n",
      "19. Kingdom         POS: PROPN  SyntR: pobj      Head: of\n",
      "20. of              POS: ADP    SyntR: prep      Head: Kingdom\n",
      "21. Yugoslavia      POS: PROPN  SyntR: pobj      Head: of\n",
      "22. during          POS: ADP    SyntR: prep      Head: mobilised\n",
      "23. World           POS: PROPN  SyntR: compound  Head: II\n",
      "24. War             POS: PROPN  SyntR: compound  Head: II\n",
      "25. II              POS: PROPN  SyntR: pobj      Head: during\n",
      "26. .               POS: PUNCT  SyntR: punct     Head: was\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.i:2}. {token.text:15} POS: {token.pos_:6} SyntR: {token.dep_:9} Head: {token.head.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e110542e-40f2-4790-a7f0-c2f5d8e871c6",
   "metadata": {},
   "source": [
    "Грамматические характеристики можно тоже посмотреть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776805fe-cd5c-4a4c-8645-dbbe5952c78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definite=Def|PronType=Art\n",
      "Degree=Pos\n",
      "Number=Sing\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:3]:\n",
    "    print(token.morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f09286f-bdbb-40a6-9d6d-a97fe05bd367",
   "metadata": {},
   "source": [
    "Также spacy позволяет разметить именованные сущности и посмотреть, что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0e48623-f8c5-4ed9-9db8-3523849d7ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: The 4th Army                   Label: ORG\n",
      "Entity: Royal Yugoslav Army            Label: ORG\n",
      "Entity: German                         Label: NORP\n",
      "Entity: the Kingdom of Yugoslavia      Label: GPE\n",
      "Entity: World War II                   Label: EVENT\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f'Entity: {ent.text:30} Label: {ent.label_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f08473f-3eed-4841-99c2-a071e037fa87",
   "metadata": {},
   "source": [
    "Если аббревиатуры вас смущают, spacy легко предоставит расшифровки (для всех!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bf71f75-8776-406f-8b43-b4df215c944f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nationalities or religious or political groups'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NORP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9873a0a-1631-468e-a7c1-a75dc902973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'object of preposition'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('pobj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d36b2-8190-4cbb-9e61-01ed637c3e34",
   "metadata": {},
   "source": [
    "Итак, а теперь самое интересное - это обертки для spacy + udpipe. UD, как известно - очень известный и влиятельный проект (чешский), цель которого - унифицировать тагсет для всех языков мира, причем как в морфологии, так и в синтаксисе. Неудивительно, что, поскольку в UD существует большое количество размеченных датасетов (русским языком активно занималась О. Ляшевская), то они обучили и свой парсер. Сам парсер написан в плюсах и не очень дружелюбен, но обертки для spacy делают жизнь проще. \n",
    "\n",
    "Внимание: я обычно это забываю, но прежде чем установить udpipe, **нужно поставить C++ Build Tools** (с сайта майкрософт, это бесплатно). Это нужно, чтобы скомпилировать udpipe из исходников в сях. Адрес сайта, откуда брать их, сам pip обычно подсказывает, но в целом можно просто погуглить. \n",
    "\n",
    "Две оболочки для udpipe, которые мы посмотрели - это spacy_udpipe и corpy. Обе нужно устанавливать:\n",
    "\n",
    "    pip install spacy_udpipe\n",
    "    pip install corpy\n",
    "    \n",
    "Для spacy_udpipe вообще ничего больше не нужно, там максимально автоматизированно скачиваются модельки. Для corpy приходится скачивать искомую модель руками, [отсюда](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-3131). Эту модель вы можете положить куда угодно, главное потом указать corpy путь к ней. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63878ad5-ea71-472c-a8fe-729c28aa0fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded a model for the 'en' language\n"
     ]
    }
   ],
   "source": [
    "import spacy_udpipe\n",
    "\n",
    "spacy_udpipe.download('en')  # эту команду достаточно выполнить только один раз - она как nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "128ec37d-b6d4-4cc1-8f0f-17c61aeef680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0. The             Lemma: the             POS: DET    SyntR: det       Head: Army\n",
      " 1. 4th             Lemma: 4th             POS: ADJ    SyntR: amod      Head: Army\n",
      " 2. Army            Lemma: Army            POS: PROPN  SyntR: nsubj     Head: formation\n",
      " 3. was             Lemma: be              POS: AUX    SyntR: cop       Head: formation\n",
      " 4. a               Lemma: a               POS: DET    SyntR: det       Head: formation\n",
      " 5. Royal           Lemma: Royal           POS: PROPN  SyntR: compound  Head: Army\n",
      " 6. Yugoslav        Lemma: Yugoslav        POS: PROPN  SyntR: compound  Head: Army\n",
      " 7. Army            Lemma: Army            POS: PROPN  SyntR: compound  Head: formation\n",
      " 8. formation       Lemma: formation       POS: NOUN   SyntR: nsubj     Head: mobilised\n",
      " 9. mobilised       Lemma: mobilise        POS: VERB   SyntR: ROOT      Head: mobilised\n",
      "10. prior           Lemma: prior           POS: ADJ    SyntR: case      Head: invasion\n",
      "11. to              Lemma: to              POS: ADP    SyntR: fixed     Head: prior\n",
      "12. the             Lemma: the             POS: DET    SyntR: det       Head: invasion\n",
      "13. German          Lemma: german          POS: ADJ    SyntR: obl:npmod Head: led\n",
      "14. -               Lemma: -               POS: PUNCT  SyntR: punct     Head: led\n",
      "15. led             Lemma: lead            POS: VERB   SyntR: amod      Head: invasion\n",
      "16. invasion        Lemma: invasion        POS: NOUN   SyntR: obl       Head: mobilised\n",
      "17. of              Lemma: of              POS: ADP    SyntR: case      Head: Kingdom\n",
      "18. the             Lemma: the             POS: DET    SyntR: det       Head: Kingdom\n",
      "19. Kingdom         Lemma: Kingdom         POS: PROPN  SyntR: nmod      Head: invasion\n",
      "20. of              Lemma: of              POS: ADP    SyntR: case      Head: Yugoslavia\n",
      "21. Yugoslavia      Lemma: Yugoslavia      POS: PROPN  SyntR: nmod      Head: Kingdom\n",
      "22. during          Lemma: during          POS: ADP    SyntR: case      Head: II\n",
      "23. World           Lemma: World           POS: PROPN  SyntR: compound  Head: War\n",
      "24. War             Lemma: War             POS: PROPN  SyntR: compound  Head: II\n",
      "25. II              Lemma: ii              POS: PROPN  SyntR: nmod      Head: Kingdom\n",
      "26. .               Lemma: .               POS: PUNCT  SyntR: punct     Head: mobilised\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy_udpipe.load('en')\n",
    "doc = nlp('The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.')\n",
    "for token in doc:\n",
    "    print(f'{token.i:2}. {token.text:15} Lemma: {token.lemma_:15} POS: {token.pos_:6} SyntR: {token.dep_:9} Head: {token.head.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc287a-9066-4f46-9339-6aae8cee0051",
   "metadata": {},
   "source": [
    "То же самое можно сделать в corpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc227ce5-556e-4365-be6d-4320ab0e102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpy.udpipe import Model\n",
    "\n",
    "model = Model('english-partut-ud-2.5-191206.udpipe')  \n",
    "# тут и нужно указать путь к вашей модели. Если она лежит в той же папке, что и скрипт, достаточно только имени файла\n",
    "\n",
    "sents = model.process('The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ff53f-ad8c-4dc4-90cf-7962b727d4b1",
   "metadata": {},
   "source": [
    "corpy возвращает генератор (то есть, итерируемый объект, который как магазин автомата, расстреляли все патроны - он опустел; повторно по генератору итерироваться нельзя). Генератор на каждом шаге выдает предложение (объект специального класса Sentence()), а в предложении - объекты класса Word(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5c65461-5421-48a5-a774-e6ed4ddcfa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<root>          Лемма: <root>          POS: <root> Грам. инфа: <root>\n",
      "The             Лемма: the             POS: DET Грам. инфа: Definite=Def|PronType=Art\n",
      "4th             Лемма: 4th             POS: ADJ Грам. инфа: Degree=Pos\n",
      "Army            Лемма: army            POS: NOUN Грам. инфа: Number=Sing\n",
      "was             Лемма: be              POS: AUX Грам. инфа: Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\n",
      "a               Лемма: a               POS: DET Грам. инфа: Definite=Ind|Number=Sing|PronType=Art\n",
      "Royal           Лемма: royal           POS: PROPN Грам. инфа: \n",
      "Yugoslav        Лемма: Yugoslav        POS: PROPN Грам. инфа: \n",
      "Army            Лемма: army            POS: PROPN Грам. инфа: \n",
      "formation       Лемма: formation       POS: NOUN Грам. инфа: Number=Sing\n",
      "mobilised       Лемма: mobilize        POS: VERB Грам. инфа: Mood=Ind|Person=3|Tense=Past|VerbForm=Fin\n",
      "prior           Лемма: prior           POS: ADJ Грам. инфа: Degree=Pos\n",
      "to              Лемма: to              POS: ADP Грам. инфа: \n",
      "the             Лемма: the             POS: DET Грам. инфа: Definite=Def|PronType=Art\n",
      "German          Лемма: German          POS: PROPN Грам. инфа: \n",
      "-               Лемма: -               POS: PUNCT Грам. инфа: \n",
      "led             Лемма: lead            POS: VERB Грам. инфа: Tense=Past|VerbForm=Part\n",
      "invasion        Лемма: invasion        POS: NOUN Грам. инфа: Number=Sing\n",
      "of              Лемма: of              POS: ADP Грам. инфа: \n",
      "the             Лемма: the             POS: DET Грам. инфа: Definite=Def|PronType=Art\n",
      "Kingdom         Лемма: kingdom         POS: NOUN Грам. инфа: Number=Sing\n",
      "of              Лемма: of              POS: ADP Грам. инфа: \n",
      "Yugoslavia      Лемма: Yugoslavia      POS: PROPN Грам. инфа: \n",
      "during          Лемма: during          POS: ADP Грам. инфа: \n",
      "World           Лемма: world           POS: NOUN Грам. инфа: Number=Sing\n",
      "War             Лемма: war             POS: NOUN Грам. инфа: Number=Sing\n",
      "II              Лемма: second          POS: ADJ Грам. инфа: Degree=Pos|NumType=Ord\n",
      ".               Лемма: .               POS: PUNCT Грам. инфа: \n",
      "Алилуя!\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    for word in sent.words:\n",
    "        print(f'{word.form:15} Лемма: {word.lemma:15} POS: {word.upostag} Грам. инфа: {word.feats}')\n",
    "print('Алилуя!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ac25ea-977d-4eb7-97cb-3ef52736ab24",
   "metadata": {},
   "source": [
    "у corpy, кстати, есть свой способ вывода имеющейся информации (хотя, по-моему, в юпитере и так красиво выводится...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1aaa1750-5aa7-429d-927c-9a0edc8b3bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence(\n",
      "   comments=[\n",
      "     '# newdoc',\n",
      "     '# newpar',\n",
      "     '# sent_id = 1',\n",
      "     '# text = The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.'],\n",
      "   words=[\n",
      "     Word(id=0, <root>),\n",
      "     Word(id=1,\n",
      "          form='The',\n",
      "          lemma='the',\n",
      "          xpostag='RD',\n",
      "          upostag='DET',\n",
      "          feats='Definite=Def|PronType=Art',\n",
      "          head=3,\n",
      "          deprel='det'),\n",
      "     Word(id=2,\n",
      "          form='4th',\n",
      "          lemma='4th',\n",
      "          xpostag='A',\n",
      "          upostag='ADJ',\n",
      "          feats='Degree=Pos',\n",
      "          head=3,\n",
      "          deprel='amod'),\n",
      "     Word(id=3,\n",
      "          form='Army',\n",
      "          lemma='army',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=9,\n",
      "          deprel='nsubj'),\n",
      "     Word(id=4,\n",
      "          form='was',\n",
      "          lemma='be',\n",
      "          xpostag='V',\n",
      "          upostag='AUX',\n",
      "          feats='Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin',\n",
      "          head=9,\n",
      "          deprel='cop'),\n",
      "     Word(id=5,\n",
      "          form='a',\n",
      "          lemma='a',\n",
      "          xpostag='RI',\n",
      "          upostag='DET',\n",
      "          feats='Definite=Ind|Number=Sing|PronType=Art',\n",
      "          head=9,\n",
      "          deprel='det'),\n",
      "     Word(id=6,\n",
      "          form='Royal',\n",
      "          lemma='royal',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=9,\n",
      "          deprel='nmod'),\n",
      "     Word(id=7,\n",
      "          form='Yugoslav',\n",
      "          lemma='Yugoslav',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=6,\n",
      "          deprel='flat'),\n",
      "     Word(id=8,\n",
      "          form='Army',\n",
      "          lemma='army',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=6,\n",
      "          deprel='flat'),\n",
      "     Word(id=9,\n",
      "          form='formation',\n",
      "          lemma='formation',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=10,\n",
      "          deprel='nsubj'),\n",
      "     Word(id=10,\n",
      "          form='mobilised',\n",
      "          lemma='mobilize',\n",
      "          xpostag='V',\n",
      "          upostag='VERB',\n",
      "          feats='Mood=Ind|Person=3|Tense=Past|VerbForm=Fin',\n",
      "          head=0,\n",
      "          deprel='root'),\n",
      "     Word(id=11,\n",
      "          form='prior',\n",
      "          lemma='prior',\n",
      "          xpostag='A',\n",
      "          upostag='ADJ',\n",
      "          feats='Degree=Pos',\n",
      "          head=10,\n",
      "          deprel='amod'),\n",
      "     Word(id=12,\n",
      "          form='to',\n",
      "          lemma='to',\n",
      "          xpostag='E',\n",
      "          upostag='ADP',\n",
      "          head=17,\n",
      "          deprel='case'),\n",
      "     Word(id=13,\n",
      "          form='the',\n",
      "          lemma='the',\n",
      "          xpostag='RD',\n",
      "          upostag='DET',\n",
      "          feats='Definite=Def|PronType=Art',\n",
      "          head=17,\n",
      "          deprel='det'),\n",
      "     Word(id=14,\n",
      "          form='German',\n",
      "          lemma='German',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=16,\n",
      "          deprel='obl',\n",
      "          misc='SpaceAfter=No'),\n",
      "     Word(id=15,\n",
      "          form='-',\n",
      "          lemma='-',\n",
      "          xpostag='FF',\n",
      "          upostag='PUNCT',\n",
      "          head=16,\n",
      "          deprel='punct',\n",
      "          misc='SpaceAfter=No'),\n",
      "     Word(id=16,\n",
      "          form='led',\n",
      "          lemma='lead',\n",
      "          xpostag='V',\n",
      "          upostag='VERB',\n",
      "          feats='Tense=Past|VerbForm=Part',\n",
      "          head=17,\n",
      "          deprel='acl'),\n",
      "     Word(id=17,\n",
      "          form='invasion',\n",
      "          lemma='invasion',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=10,\n",
      "          deprel='obl'),\n",
      "     Word(id=18,\n",
      "          form='of',\n",
      "          lemma='of',\n",
      "          xpostag='E',\n",
      "          upostag='ADP',\n",
      "          head=20,\n",
      "          deprel='case'),\n",
      "     Word(id=19,\n",
      "          form='the',\n",
      "          lemma='the',\n",
      "          xpostag='RD',\n",
      "          upostag='DET',\n",
      "          feats='Definite=Def|PronType=Art',\n",
      "          head=20,\n",
      "          deprel='det'),\n",
      "     Word(id=20,\n",
      "          form='Kingdom',\n",
      "          lemma='kingdom',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=17,\n",
      "          deprel='nmod'),\n",
      "     Word(id=21,\n",
      "          form='of',\n",
      "          lemma='of',\n",
      "          xpostag='E',\n",
      "          upostag='ADP',\n",
      "          head=22,\n",
      "          deprel='case'),\n",
      "     Word(id=22,\n",
      "          form='Yugoslavia',\n",
      "          lemma='Yugoslavia',\n",
      "          xpostag='SP',\n",
      "          upostag='PROPN',\n",
      "          head=20,\n",
      "          deprel='nmod'),\n",
      "     Word(id=23,\n",
      "          form='during',\n",
      "          lemma='during',\n",
      "          xpostag='E',\n",
      "          upostag='ADP',\n",
      "          head=25,\n",
      "          deprel='case'),\n",
      "     Word(id=24,\n",
      "          form='World',\n",
      "          lemma='world',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=25,\n",
      "          deprel='nmod'),\n",
      "     Word(id=25,\n",
      "          form='War',\n",
      "          lemma='war',\n",
      "          xpostag='S',\n",
      "          upostag='NOUN',\n",
      "          feats='Number=Sing',\n",
      "          head=10,\n",
      "          deprel='obl'),\n",
      "     Word(id=26,\n",
      "          form='II',\n",
      "          lemma='second',\n",
      "          xpostag='NO',\n",
      "          upostag='ADJ',\n",
      "          feats='Degree=Pos|NumType=Ord',\n",
      "          head=25,\n",
      "          deprel='amod',\n",
      "          misc='SpaceAfter=No'),\n",
      "     Word(id=27,\n",
      "          form='.',\n",
      "          lemma='.',\n",
      "          xpostag='FS',\n",
      "          upostag='PUNCT',\n",
      "          head=10,\n",
      "          deprel='punct',\n",
      "          misc='SpaceAfter=No')])]\n"
     ]
    }
   ],
   "source": [
    "from corpy.udpipe import pprint\n",
    "\n",
    "pprint(list(model.process('The 4th Army was a Royal Yugoslav Army formation mobilised prior to the German-led invasion of the Kingdom of Yugoslavia during World War II.')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
